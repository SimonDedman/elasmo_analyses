#!/usr/bin/env python3
"""
extract_firefox_cookies.py

Extract cookies from Firefox profile and save in Netscape format.

IMPORTANT: Close Firefox before running this script!
Firefox locks the cookies database while it's running.

Usage:
    python3 scripts/extract_firefox_cookies.py

    # Or specify domains
    python3 scripts/extract_firefox_cookies.py --domains sciencedirect.com wiley.com peerj.com

Author: Simon Dedman
Date: 2025-10-21
Version: 1.0
"""

import sqlite3
import os
import shutil
import argparse
from pathlib import Path
from datetime import datetime

def find_firefox_profile():
    """
    Find Firefox profile directory.

    Returns:
        Path to Firefox profile, or None if not found
    """
    # Linux/Mac
    firefox_dir = Path.home() / ".mozilla/firefox"

    if not firefox_dir.exists():
        # Windows
        firefox_dir = Path.home() / "AppData/Roaming/Mozilla/Firefox/Profiles"

    if not firefox_dir.exists():
        print("‚ùå Firefox profile directory not found!")
        print(f"   Searched: {firefox_dir}")
        return None

    # Look for default-release profile first
    profiles = list(firefox_dir.glob("*.default-release"))

    if not profiles:
        # Fall back to default profile
        profiles = list(firefox_dir.glob("*.default"))

    if not profiles:
        # Fall back to any profile
        profiles = [p for p in firefox_dir.iterdir() if p.is_dir()]

    if not profiles:
        print("‚ùå No Firefox profiles found!")
        return None

    profile = profiles[0]
    print(f"‚úÖ Found Firefox profile: {profile.name}")
    return profile

def extract_cookies(profile_path, domains=None, output_file='cookies.txt'):
    """
    Extract cookies from Firefox SQLite database.

    Args:
        profile_path: Path to Firefox profile
        domains: List of domains to extract (None = all domains)
        output_file: Output filename
    """
    cookies_db = profile_path / "cookies.sqlite"

    if not cookies_db.exists():
        print(f"‚ùå Cookies database not found: {cookies_db}")
        return False

    print(f"üìÇ Cookies database: {cookies_db}")

    # Copy database (Firefox locks it while running)
    temp_db = "/tmp/firefox_cookies_temp.sqlite"

    try:
        shutil.copy2(cookies_db, temp_db)
    except PermissionError:
        print("‚ùå Cannot copy cookies database!")
        print("   Firefox may be running - please close Firefox and try again.")
        return False

    # Extract cookies
    try:
        conn = sqlite3.connect(temp_db)
        cursor = conn.cursor()

        # Write Netscape format header
        with open(output_file, 'w') as f:
            f.write("# Netscape HTTP Cookie File\n")
            f.write("# This file was generated by extract_firefox_cookies.py\n")
            f.write(f"# Extracted: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("# https://curl.haxx.se/rfc/cookie_spec.html\n\n")

            cookie_count = 0

            if domains:
                # Extract cookies for specified domains
                for domain in domains:
                    cursor.execute("""
                        SELECT host,
                               CASE WHEN host LIKE '.%' THEN 'TRUE' ELSE 'FALSE' END,
                               path,
                               CASE WHEN isSecure = 1 THEN 'TRUE' ELSE 'FALSE' END,
                               expiry,
                               name,
                               value
                        FROM moz_cookies
                        WHERE host LIKE ?
                        ORDER BY host, path, name
                    """, (f'%{domain}%',))

                    rows = cursor.fetchall()

                    if rows:
                        f.write(f"# Cookies for {domain}\n")
                        for row in rows:
                            f.write('\t'.join(str(x) for x in row) + '\n')
                            cookie_count += 1
                        f.write('\n')
                    else:
                        print(f"‚ö†Ô∏è  No cookies found for {domain}")
            else:
                # Extract all cookies
                cursor.execute("""
                    SELECT host,
                           CASE WHEN host LIKE '.%' THEN 'TRUE' ELSE 'FALSE' END,
                           path,
                           CASE WHEN isSecure = 1 THEN 'TRUE' ELSE 'FALSE' END,
                           expiry,
                           name,
                           value
                    FROM moz_cookies
                    ORDER BY host, path, name
                """)

                for row in cursor.fetchall():
                    f.write('\t'.join(str(x) for x in row) + '\n')
                    cookie_count += 1

        conn.close()
        os.remove(temp_db)

        if cookie_count > 0:
            print(f"\n‚úÖ Extracted {cookie_count} cookies to {output_file}")
            return True
        else:
            print(f"\n‚ö†Ô∏è  No cookies found!")
            return False

    except Exception as e:
        print(f"‚ùå Error extracting cookies: {e}")
        if os.path.exists(temp_db):
            os.remove(temp_db)
        return False

def main():
    parser = argparse.ArgumentParser(
        description='Extract cookies from Firefox profile',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
    # Extract cookies for key publisher domains
    python3 scripts/extract_firefox_cookies.py --domains sciencedirect.com elsevier.com wiley.com peerj.com

    # Extract all cookies
    python3 scripts/extract_firefox_cookies.py --all

    # Specify output file
    python3 scripts/extract_firefox_cookies.py --output my_cookies.txt --domains sciencedirect.com

After extracting, use with retry script:
    python3 scripts/retry_failed_downloads.py --status error --domain sciencedirect --cookies cookies.txt
        """
    )

    parser.add_argument(
        '--domains',
        nargs='+',
        default=['sciencedirect.com', 'elsevier.com', 'wiley.com', 'peerj.com',
                 'tandfonline.com', 'springer.com', 'nature.com'],
        help='Domains to extract cookies from (default: major publishers)'
    )

    parser.add_argument(
        '--all',
        action='store_true',
        help='Extract all cookies (not just specified domains)'
    )

    parser.add_argument(
        '--output',
        default='cookies.txt',
        help='Output file (default: cookies.txt)'
    )

    args = parser.parse_args()

    print("=" * 80)
    print("FIREFOX COOKIE EXTRACTOR")
    print("=" * 80)
    print("\n‚ö†Ô∏è  IMPORTANT: Close Firefox before running this script!\n")

    # Find Firefox profile
    profile = find_firefox_profile()
    if not profile:
        return

    # Extract cookies
    domains = None if args.all else args.domains

    if domains:
        print(f"\nüìã Extracting cookies for domains:")
        for domain in domains:
            print(f"   ‚Ä¢ {domain}")
    else:
        print("\nüìã Extracting ALL cookies")

    print()

    success = extract_cookies(profile, domains, args.output)

    if success:
        print("\n" + "=" * 80)
        print("NEXT STEPS")
        print("=" * 80)
        print("\n1. Test with a small sample:")
        print(f"   python3 scripts/retry_failed_downloads.py \\")
        print(f"       --status error \\")
        print(f"       --domain sciencedirect \\")
        print(f"       --cookies {args.output} \\")
        print(f"       --max-papers 5")
        print("\n2. If successful, run full retry:")
        print(f"   python3 scripts/retry_failed_downloads.py \\")
        print(f"       --status error \\")
        print(f"       --domain sciencedirect \\")
        print(f"       --cookies {args.output}")
        print("=" * 80)

if __name__ == "__main__":
    main()
